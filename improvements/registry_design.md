# Progy Official Registry Implementation Plan

## 1. Executive Summary & Goals

This document outlines the comprehensive architectural design and implementation strategy for the **Progy Official Registry**. The primary objective is to transition from the current decentralized, Git-based distribution model to a centralized, performant registry system leveraging **Cloudflare D1** for metadata management and **Cloudflare R2** for artifact storage.

### Key Objectives

1.  **Centralization:** Establish a single source of truth for all official and community courses.
2.  **Performance:** Utilize R2's global CDN capabilities to serve course content faster than raw Git clones.
3.  **Decoupling:** Separate the _course source code_ (immutable, versioned artifacts) from the _student's progress_ (mutable, personal Git history).
4.  **Versioning:** Enforce Semantic Versioning (SemVer) to allow instructors to patch courses without breaking existing student environments.
5.  **Ownership:** Introduce a strict `@username/slug` namespacing system to prevent collisions and ensure clear attribution.

### The "Portfolio Mode" Shift

Currently, students clone an instructor's repository and build on top of it. This often leads to confusion when the upstream repo changes or when students want to showcase their work as their own project.

**The New Workflow:**

1.  **Instructor:**
    - Develops the course locally.
    - Runs `progy pack` to generate a compiled `.progy` artifact.
    - Runs `progy publish` to upload the `.progy` file to the Registry.
2.  **Registry:** Stores `v1.0.0.progy` in R2 and records metadata in D1.
3.  **Student:** Runs `progy init @diego/rust-mastery`.
4.  **CLI:** Downloads the `.progy` file.
5.  **CLI:** Unpacks the artifact using `CourseContainer` logic.
6.  **CLI:** Initializes a _fresh_ Git repository in the student's folder.
7.  **CLI:** Helps the student push this new repo to their own GitHub as a "Portfolio Project".
8.  **Result:** The student owns the code 100%. The instructor owns the distribution channel.

---

## 2. Architecture & Tech Stack

The registry is built on the existing Progy infrastructure, adding new capabilities to the Backend and CLI.

### Components

- **Backend (Apps/Backend):**
  - **Runtime:** Cloudflare Workers (Hono framework).
  - **Database:** Cloudflare D1 (SQLite).
  - **Storage:** Cloudflare R2 (Object Storage).
  - **Auth:** Existing Better-Auth integration.
- **CLI (Apps/CLI):**
  - **Language:** TypeScript (Bun runtime).
  - **Libraries:** `adm-zip` for archiving (used internally by `CourseContainer`), `commander` for CLI parsing.
- **Frontend (Apps/Web - Future):**
  - A "Marketplace" view to browse registry packages.

### Storage Strategy: `.progy` Artifacts

We will use **`.progy` files** as the exclusive distribution format.

- **What is a `.progy` file?** It is a standardized Zip archive containing the course content, runner configuration, and metadata, optimized for distribution. It is generated by the `progy pack` command.
- **Why not raw Zips?** Using a branded extension (`.progy`) enforces the idea that this is a compiled course artifact, not just a random folder backup. It allows us to add internal metadata or encryption in the future if needed.
- **Path Format:** `packages/@<username>/<slug>/v<version>.progy`
  - Example: `packages/@diego/rust-mastery/v1.0.0.progy`

---

## 3. Database Schema Design (Cloudflare D1)

We need to introduce three new tables to `apps/backend/src/db/schema.ts` to manage the registry state.

### 3.1 `registry_packages`

This table stores the high-level metadata for a course. It acts as the "Catalog Entry".

```typescript
// apps/backend/src/db/schema.ts

import {
  sqliteTable,
  text,
  integer,
  uniqueIndex,
  index,
} from 'drizzle-orm/sqlite-core';
import { user } from './auth-schema'; // Assuming user table is imported

export const registryPackages = sqliteTable(
  'registry_packages',
  {
    // UUID for the package
    id: text('id').primaryKey(),

    // The owner of the package (must match the @scope)
    userId: text('user_id')
      .notNull()
      .references(() => user.id),

    // The full package name, e.g., "@diego/rust-mastery"
    name: text('name').notNull(),

    // The URL-friendly slug, e.g., "rust-mastery"
    slug: text('slug').notNull(),

    // Short description for the CLI search
    description: text('description'),

    // Cached latest version to avoid joining tables on simple listings
    latestVersion: text('latest_version'),

    // Visibility flag
    isPublic: integer('is_public', { mode: 'boolean' }).default(true),

    // Timestamps
    createdAt: integer('created_at', { mode: 'timestamp' })
      .notNull()
      .$defaultFn(() => new Date()),
    updatedAt: integer('updated_at', { mode: 'timestamp' })
      .notNull()
      .$defaultFn(() => new Date()),
  },
  (table) => ({
    // Ensure strict uniqueness on the full package name
    uniqueName: uniqueIndex('registry_packages_name_idx').on(table.name),
    // Optimize lookups for "My Courses" dashboard
    userIdIdx: index('registry_packages_user_id_idx').on(table.userId),
  }),
);
```

### 3.2 `registry_versions`

This table stores the immutable history of every published version.

```typescript
export const registryVersions = sqliteTable(
  'registry_versions',
  {
    id: text('id').primaryKey(),

    // Link to parent package
    packageId: text('package_id')
      .notNull()
      .references(() => registryPackages.id),

    // The SemVer string, e.g., "1.0.0"
    version: text('version').notNull(),

    // The R2 path to the .progy file
    storageKey: text('storage_key').notNull(),

    // File size in bytes (for progress bars/quotas)
    sizeBytes: integer('size_bytes').notNull(),

    // SHA-256 Checksum for integrity verification
    checksum: text('checksum').notNull(),

    // Release notes / Changelog from the CLI
    changelog: text('changelog'),

    createdAt: integer('created_at', { mode: 'timestamp' })
      .notNull()
      .$defaultFn(() => new Date()),
  },
  (table) => ({
    // Ensure a version number is unique within a package
    uniqueVersion: uniqueIndex('registry_versions_pkg_ver_idx').on(
      table.packageId,
      table.version,
    ),
  }),
);
```

### 3.3 `registry_downloads`

(Optional for MVP, but recommended for analytics)
Tracks who is downloading what version and when.

```typescript
export const registryDownloads = sqliteTable('registry_downloads', {
  id: text('id').primaryKey(),
  packageId: text('package_id').notNull(),
  versionId: text('version_id').notNull(),

  // Nullable if we allow anonymous downloads (e.g. CLI without login)
  userId: text('user_id'),

  ipAddress: text('ip_address'),

  // Analytics
  downloadedAt: integer('downloaded_at', { mode: 'timestamp' })
    .notNull()
    .$defaultFn(() => new Date()),
});
```

---

## 4. Backend API Implementation (`apps/backend`)

We will create a new route file `apps/backend/src/endpoints/registry.ts` and mount it at `/registry` in `index.ts`.

### 4.1 Dependency Injection

Update `wrangler.toml` and `env` interface to include the R2 binding.

```toml
# apps/backend/wrangler.toml
[[r2_buckets]]
binding = "R2"
bucket_name = "progy-registry-prod"
```

```typescript
// apps/backend/src/env.ts
export interface CloudflareBindings {
  DB: D1Database;
  R2: R2Bucket;
  // ... existing bindings
}
```

### 4.2 API Endpoint: Publish (`POST /registry/publish`)

This is the most critical endpoint. It handles the upload of a new version.

**Request Flow:**

1.  **Auth:** Verify `Authorization` header.
2.  **Parse:** Read `Multipart/Form-Data`.
    - `file`: The `.progy` blob.
    - `metadata`: JSON string `{ "name": "@scope/slug", "version": "1.0.0", "description": "..." }`.
3.  **Validate:**
    - Name format matches `@username/slug`.
    - User owns `@username`.
    - Version is valid SemVer.
    - Version does not already exist (Immutable versions!).
    - File extension is `.progy` (optional check, but good for hygiene).
4.  **Storage:**
    - Generate path: `packages/@scope/slug/v1.0.0.progy`.
    - Stream file to R2.
5.  **Database:**
    - Insert into `registry_packages` (if new).
    - Insert into `registry_versions`.
    - Update `latestVersion` in `registry_packages`.

**Code Implementation (Draft):**

```typescript
// apps/backend/src/endpoints/registry.ts
import { Hono } from 'hono';
import { drizzle } from 'drizzle-orm/d1';
import { eq, and } from 'drizzle-orm';
import { registryPackages, registryVersions } from '../db/schema';

const registry = new Hono<{ Bindings: CloudflareBindings }>();

registry.post('/publish', async (c) => {
  const user = c.get('user');
  if (!user) return c.json({ error: 'Unauthorized' }, 401);

  const body = await c.req.parseBody();
  const file = body['file'];
  const metaStr = body['metadata'] as string;

  if (!file || !(file instanceof File)) {
    return c.json({ error: 'Invalid file upload' }, 400);
  }

  // 1. Parse Metadata
  let metadata;
  try {
    metadata = JSON.parse(metaStr);
  } catch (e) {
    return c.json({ error: 'Invalid metadata JSON' }, 400);
  }

  // 2. Validate Naming (@scope/slug)
  const nameParts = metadata.name.split('/');
  if (nameParts.length !== 2 || !nameParts[0].startsWith('@')) {
    return c.json(
      { error: 'Invalid package name. Must be @username/slug' },
      400,
    );
  }
  const scope = nameParts[0].substring(1); // "diego"

  // TODO: Validate that 'scope' matches user.username (or allowed orgs)

  const db = drizzle(c.env.DB);

  // 3. Find/Create Package
  let pkg = await db
    .select()
    .from(registryPackages)
    .where(eq(registryPackages.name, metadata.name))
    .get();

  if (!pkg) {
    const newId = crypto.randomUUID();
    await db.insert(registryPackages).values({
      id: newId,
      userId: user.id,
      name: metadata.name,
      slug: nameParts[1],
      description: metadata.description || '',
      isPublic: !metadata.private,
      latestVersion: metadata.version,
    });
    pkg = { id: newId };
  } else {
    // Check ownership
    if (pkg.userId !== user.id) {
      return c.json(
        { error: 'Permission denied: You do not own this package.' },
        403,
      );
    }
  }

  // 4. Check for Version Conflict
  const existing = await db
    .select()
    .from(registryVersions)
    .where(
      and(
        eq(registryVersions.packageId, pkg.id),
        eq(registryVersions.version, metadata.version),
      ),
    )
    .get();

  if (existing) {
    return c.json(
      {
        error: `Version ${metadata.version} already exists. Please increment version in course.json`,
      },
      409,
    );
  }

  // 5. Upload to R2
  const key = `packages/${metadata.name}/${metadata.version}.progy`;
  await c.env.R2.put(key, await file.arrayBuffer(), {
    httpMetadata: { contentType: 'application/octet-stream' }, // Or application/zip if we want to be explicit
    customMetadata: { userId: user.id, version: metadata.version },
  });

  // 6. Record Version
  await db.insert(registryVersions).values({
    id: crypto.randomUUID(),
    packageId: pkg.id,
    version: metadata.version,
    storageKey: key,
    sizeBytes: file.size,
    checksum: 'sha256-placeholder', // Compute this if possible
    changelog: metadata.changelog,
  });

  // 7. Update Head
  await db
    .update(registryPackages)
    .set({ latestVersion: metadata.version, updatedAt: new Date() })
    .where(eq(registryPackages.id, pkg.id));

  return c.json({ success: true, version: metadata.version });
});
```

### 4.3 API Endpoint: Resolve (`GET /registry/resolve/:name`)

Used by the CLI to find the latest version and metadata before downloading.

```typescript
registry.get('/resolve/:scope/:slug', async (c) => {
  const name = `@${c.req.param('scope')}/${c.req.param('slug')}`;
  const db = drizzle(c.env.DB);

  const pkg = await db
    .select()
    .from(registryPackages)
    .where(eq(registryPackages.name, name))
    .get();

  if (!pkg) return c.json({ error: 'Package not found' }, 404);

  // Get versions list
  const versions = await db
    .select({ v: registryVersions.version })
    .from(registryVersions)
    .where(eq(registryVersions.packageId, pkg.id))
    .orderBy(desc(registryVersions.createdAt))
    .all();

  return c.json({
    name: pkg.name,
    latest: pkg.latestVersion,
    versions: versions.map((v) => v.v),
    description: pkg.description,
  });
});
```

### 4.4 API Endpoint: Download (`GET /registry/download/:name/:version`)

Streams the file content.

```typescript
registry.get('/download/:scope/:slug/:version', async (c) => {
  const name = `@${c.req.param('scope')}/${c.req.param('slug')}`;
  const version = c.req.param('version');
  const key = `packages/${name}/${version}.progy`;

  const object = await c.env.R2.get(key);
  if (!object)
    return c.json({ error: 'Artifact not found in registry storage' }, 404);

  // Add analytics tracking here (fire-and-forget async)

  return new Response(object.body, {
    headers: {
      'Content-Type': 'application/octet-stream',
      'Content-Disposition': `attachment; filename="${c.req.param('slug')}-${version}.progy"`,
    },
  });
});
```

---

## 5. CLI Implementation (`apps/cli`)

### 5.1 The `progy pack` Command

This command already exists but needs to be the strict precursor to publishing.

**File:** `apps/cli/src/commands/course.ts` (pack function)

**Logic:**

1.  Validates `course.json`.
2.  Compresses the course directory into a `.progy` file (zip format).
3.  Ensures strictly required files (`course.json`, `content/`) are present.
4.  Excludes `node_modules`, `.git`, etc.

### 5.2 Command: `progy publish`

This command is for instructors. It takes the _pre-built_ `.progy` artifact and uploads it.

**File:** `apps/cli/src/commands/publish.ts`

**Steps:**

1.  **Check:** Does a `.progy` file exist?
    - If no, run `progy pack` automatically (convenience) or ask user to run it.
2.  **Validation:**
    - Read `course.json` _from inside_ the `.progy` file (or assume the one in CWD matches).
    - Check `name` and `version`.
    - Ensure user is logged in (`loadToken()`).
3.  **Upload:**
    - `POST /registry/publish`
    - FormData: `file=blob`, `metadata=JSON.stringify({...})`.
    - Show progress bar.

**Code Snippet (Publish Logic):**

```typescript
import { createReadStream } from 'node:fs';

export async function publish() {
  // 1. Ensure Pack
  const cwd = process.cwd();
  const config = await CourseLoader.validateCourse(cwd);
  const progyFile = `${config.id}.progy`;

  if (!(await exists(progyFile))) {
    logger.info('Packing course...');
    await CourseContainer.pack(cwd, resolve(progyFile));
  }

  // 2. Prepare Upload
  const token = await loadToken();
  const file = Bun.file(progyFile);

  const formData = new FormData();
  formData.append('file', file);
  formData.append(
    'metadata',
    JSON.stringify({
      name: config.name,
      version: config.version,
      description: config.description,
    }),
  );

  // 3. Send
  logger.info(`Publishing ${config.name} v${config.version}...`);
  const res = await fetch(`${BACKEND_URL}/registry/publish`, {
    method: 'POST',
    headers: { Authorization: `Bearer ${token}` },
    body: formData,
  });

  if (!res.ok) {
    const err = await res.json();
    logger.error('Publish failed', err.error);
    return;
  }

  logger.success('Published successfully!');
}
```

### 5.3 Command: `progy init <package>` (The Student Flow)

This replaces the old `git clone` logic.

**File:** `apps/cli/src/commands/course.ts` (init function)

**New Flow:**

1.  **Parse Argument:** `progy init @diego/rust`.
2.  **Resolve:** Call `GET /registry/resolve/@diego/rust` to get the latest version.
3.  **Download:** Call `GET /registry/download/@diego/rust/1.0.0`.
    - Stream the response to a temporary file (e.g., `/tmp/course.progy`).
4.  **Unpack:** Use `CourseContainer.unpack` to extract the `.progy` file to `./rust`.
5.  **Portfolio Setup (The Git Logic):**
    - **Step A:** `git init` in the new folder.
    - **Step B:** Create an initial commit.
      - `git add .`
      - `git commit -m "Initial commit from Progy Registry (v1.0.0)"`
    - **Step C:** (Optional) Ask user: _"Do you want to connect this to GitHub?"_
      - If YES:
        - Use existing `apps/backend/src/endpoints/git.ts` logic to create a **new** private repo on the **student's** GitHub account (e.g., `progy-rust-portfolio`).
        - `git remote add origin <new-repo-url>`
        - `git push -u origin main`
    - **Result:** The student has a clean git history starting from the moment they downloaded the course. They are _not_ attached to the instructor's history.

**Detailed 'Portfolio Mode' Logic:**

```typescript
// apps/cli/src/utils/git-setup.ts

export async function setupStudentPortfolio(
  cwd: string,
  courseName: string,
  token: string,
) {
  logger.info('Initializing your personal portfolio repository...', 'GIT');

  // 1. Local Init
  await GitUtils.exec(['init'], cwd);
  await GitUtils.exec(['add', '.'], cwd);
  await GitUtils.exec(['commit', '-m', `Start course: ${courseName}`], cwd);

  // 2. Remote Creation (Interactive)
  const shouldConnect = await confirm({
    message: 'Create a private GitHub repository for this course?',
  });
  if (!shouldConnect) return;

  try {
    // Reuse existing backend endpoint that creates a repo
    const res = await fetch(`${BACKEND_URL}/git/ensure-repo`, {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${token}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ courseId: courseName.replace('/', '-') }),
    });

    const data = await res.json();
    if (!data.repoUrl) throw new Error('Failed to create remote repo');

    // 3. Link & Push
    await GitUtils.exec(['remote', 'add', 'origin', data.repoUrl], cwd);
    await GitUtils.exec(['branch', '-M', 'main'], cwd);
    await GitUtils.exec(['push', '-u', 'origin', 'main'], cwd);

    logger.success(`Linked to GitHub: ${data.htmlUrl}`);
  } catch (e) {
    logger.error('Failed to setup GitHub remote', e.message);
  }
}
```

---

## 6. Migration & Compatibility

### Changes to `course.json`

We need to enforce strict schema validation for the new registry fields.

```json
{
  "name": "@diego/rust-basics", // MUST be scoped
  "version": "1.0.1", // MUST be semver
  "description": "A beginner course for Rust",
  "private": false // Future proofing
}
```

### Transition Plan

1.  **Phase 1 (Hybrid):**
    - Keep `COURSES` in `wrangler.toml` as a fallback.
    - Update CLI to check Registry API first.
    - If Registry 404s, fall back to the hardcoded GitHub list.
2.  **Phase 2 (Migration):**
    - Script to pull all repos from `COURSES`, run `progy pack`, and upload them to the Registry as `v1.0.0` under a system account (e.g., `@progy`).
3.  **Phase 3 (Deprecation):**
    - Remove `COURSES` from `wrangler.toml`.

---

## 7. Security & Validation

### Authentication

- **Publishing:** Strictly requires a valid session token.
- **Downloading:** Currently public (for free courses). Future: Verify "purchased" status for paid courses before returning the download stream.

### File Validation

- **Max Size:** Limit `.progy` uploads to 100MB (to prevent abuse of R2/Workers KV).
- **Content:** Scan zip (server-side) to ensure it contains `course.json` at root before accepting.
- **Malware:** (Future) Scan for executable binaries in the zip.

### Rate Limiting

- Apply rate limits to `/publish` to prevent spam (e.g., 10 versions/hour).
- Apply rate limits to `/download` by IP.

---

## 8. Detailed Migration SQL

To manually migrate the database or create the new tables, use the following SQL. This is useful for `wrangler d1 execute`.

```sql
-- Migration: Add Registry Tables

-- 1. Create Packages Table
CREATE TABLE IF NOT EXISTS registry_packages (
    id TEXT PRIMARY KEY NOT NULL,
    user_id TEXT NOT NULL REFERENCES user(id),
    name TEXT NOT NULL UNIQUE,
    slug TEXT NOT NULL,
    description TEXT,
    latest_version TEXT,
    is_public INTEGER DEFAULT 1,
    created_at INTEGER NOT NULL DEFAULT (unixepoch()),
    updated_at INTEGER NOT NULL DEFAULT (unixepoch())
);

-- 2. Create Index for Packages
CREATE INDEX IF NOT EXISTS registry_packages_user_id_idx ON registry_packages(user_id);
CREATE UNIQUE INDEX IF NOT EXISTS registry_packages_name_idx ON registry_packages(name);

-- 3. Create Versions Table
CREATE TABLE IF NOT EXISTS registry_versions (
    id TEXT PRIMARY KEY NOT NULL,
    package_id TEXT NOT NULL REFERENCES registry_packages(id),
    version TEXT NOT NULL,
    storage_key TEXT NOT NULL,
    size_bytes INTEGER NOT NULL,
    checksum TEXT NOT NULL,
    changelog TEXT,
    created_at INTEGER NOT NULL DEFAULT (unixepoch())
);

-- 4. Create Index for Versions
CREATE UNIQUE INDEX IF NOT EXISTS registry_versions_pkg_ver_idx ON registry_versions(package_id, version);

-- 5. Create Downloads Table (Optional)
CREATE TABLE IF NOT EXISTS registry_downloads (
    id TEXT PRIMARY KEY NOT NULL,
    package_id TEXT NOT NULL,
    version_id TEXT NOT NULL,
    user_id TEXT,
    ip_address TEXT,
    downloaded_at INTEGER NOT NULL DEFAULT (unixepoch())
);
```

---

## 9. Error Code Reference

The backend API will return specific error codes to help the CLI provide better feedback.

| HTTP Code | Error Code          | Message                                          | Description                                         |
| :-------- | :------------------ | :----------------------------------------------- | :-------------------------------------------------- |
| 400       | `INVALID_NAME`      | "Invalid package name. Must be @username/slug"   | Malformed package name in metadata.                 |
| 400       | `INVALID_VERSION`   | "Invalid semantic version"                       | Version does not follow SemVer (x.y.z).             |
| 401       | `UNAUTHORIZED`      | "Unauthorized"                                   | Session token missing or invalid.                   |
| 403       | `FORBIDDEN`         | "Permission denied: You do not own this package" | User tries to publish to a scope they don't own.    |
| 404       | `PACKAGE_NOT_FOUND` | "Package not found"                              | Package ID or name does not exist.                  |
| 409       | `VERSION_EXISTS`    | "Version already exists"                         | Attempt to overwrite an existing immutable version. |
| 413       | `PAYLOAD_TOO_LARGE` | "File too large"                                 | Upload exceeds the 100MB limit.                     |
| 500       | `R2_UPLOAD_FAILED`  | "Storage upload failed"                          | Internal error communicating with R2.               |

---

## 10. Client-Side Caching Strategy

To improve performance and reduce R2 bandwidth, the CLI should implement a local cache.

### Local Cache Directory

On macOS/Linux: `~/.progy/cache/registry/`
On Windows: `%LOCALAPPDATA%\progy\cache\registry\`

### Cache Logic

1.  **Resolve:** When `progy init` runs, it gets the latest version (e.g., `1.0.0`) and its checksum.
2.  **Check Cache:** Look for `~/.progy/cache/registry/@scope/slug/1.0.0.progy`.
3.  **Verify:** If found, compute SHA-256 of the cached file.
    - If matches checksum from API -> Use cached file (HIT).
    - If mismatch -> Delete and re-download (MISS).
4.  **Download:** If not found, download from API and save to cache.

**Pruning:**
A background process (or on every execution) should check the cache size. If it exceeds 1GB, delete the oldest accessed files (LRU).

---

## 11. Course Metadata Specification (`course.json`)

The `course.json` file is the manifest for every package.

```json
{
  "$schema": "https://progy.dev/schema/course.json",
  "name": "@diego/rust-mastery",
  "version": "1.0.0",
  "description": "The ultimate guide to Rust programming.",
  "keywords": ["rust", "systems", "webassembly"],
  "author": {
    "name": "Diego",
    "email": "diego@example.com",
    "url": "https://diego.dev"
  },
  "license": "MIT",
  "private": false,
  "repository": {
    "type": "git",
    "url": "https://github.com/diego/rust-mastery.git"
  },
  "engines": {
    "progy": ">=0.15.0"
  },
  "files": ["content/**/*", "runner/**/*", "assets/**/*", "README.md"]
}
```

### Fields Explanation

- `name`: **Required.** Must match the Registry ID format.
- `version`: **Required.** SemVer.
- `files`: **Optional.** Glob patterns to include in the published zip. If omitted, defaults to everything except `.gitignore` rules.
- `engines`: **Optional.** Specifies compatible Progy CLI versions.

---

## 12. Environment Setup Guide

For developers contributing to the Progy Registry codebase.

### Prerequisites

- Wrangler CLI (`npm install -g wrangler`)
- Cloudflare Account (Free Tier works)

### Step 1: Create D1 Database

```bash
wrangler d1 create progy-db
# Copy the database_id to wrangler.toml
```

### Step 2: Create R2 Bucket

```bash
wrangler r2 bucket create progy-registry-prod
# Add binding to wrangler.toml
```

### Step 3: Local Development

```bash
# Start local D1 and R2 emulation
bun run dev:backend
```

The local backend will emulate R2 using local disk storage, allowing full testing of the publish/download flow without hitting Cloudflare limits.

---

## 13. Testing Strategy

We must ensure the registry is reliable.

### Backend Tests (`apps/backend/tests/registry.test.ts`)

- **Unit Tests:**
  - Test SemVer validation regex.
  - Test Package Name validation regex (`@scope/slug`).
- **Integration Tests:**
  - Mock `c.env.DB` and `c.env.BUCKET`.
  - `POST /publish` with valid data -> 200 OK.
  - `POST /publish` with duplicate version -> 409 Conflict.
  - `POST /publish` with mismatching user -> 403 Forbidden.

### CLI Tests (`apps/cli/tests/registry.test.ts`)

- **Mock Server:** Spin up a local Hono server mocking the Registry API.
- **Flow Test:**
  1.  Run `progy publish` in a test folder.
  2.  Assert `POST /publish` was called with correct FormData.
  3.  Assert zip file structure (contains `course.json`).
- **Init Test:**
  1.  Run `progy init @test/pkg`.
  2.  Assert `GET /resolve` called.
  3.  Assert `GET /download` called.
  4.  Assert folder created and `git init` run.

---

## 14. Advanced CLI Usage

### `--dry-run`

Simulates a publish without uploading.

```bash
progy publish --dry-run
# Output:
# [DRY-RUN] Validating course.json... OK
# [DRY-RUN] Packing files... (3.2MB)
# [DRY-RUN] Would publish @diego/rust-mastery v1.0.0
```

### `--force` (Admin Only)

Overrides version checks or ownership (if admin).

```bash
progy publish --force
```

### `--json`

Outputs result in JSON for CI/CD pipelines.

```bash
progy publish --json
# Output: { "success": true, "version": "1.0.0", "url": "..." }
```

---

## 15. Future Improvements (Post-MVP)

1.  **Web UI:** A marketplace to browse courses, view readmes, and see version history.
2.  **Course Updates:**
    - Command: `progy update`
    - Logic: Checks for new version -> Downloads patch -> Attempts to merge changes into student's repo using `git merge-file`.
3.  **Monetization:**
    - Gate the `/download` endpoint behind a Stripe purchase check.
    - "Buy this course for $10" -> Adds record to `user_purchases` table -> API verifies before returning stream.

## 16. Implementation Checklist & file Changes

### backend/src/db/schema.ts

- [ ] Import `user` table.
- [ ] Define `registryPackages`.
- [ ] Define `registryVersions`.
- [ ] Define `registryDownloads`.
- [ ] Export new tables.

### backend/src/index.ts

- [ ] Import `registry` router.
- [ ] Mount `app.route('/registry', registry)`.

### backend/src/endpoints/registry.ts (New)

- [ ] Implement `POST /publish`.
- [ ] Implement `GET /resolve/:scope/:slug`.
- [ ] Implement `GET /download/:scope/:slug/:version`.

### cli/src/commands/publish.ts (New)

- [ ] Implement argument parsing.
- [ ] Implement `packCourse` (zip logic).
- [ ] Implement API upload client.

### cli/src/commands/course.ts (Update)

- [ ] Modify `init` to detect registry pattern.
- [ ] Implement `downloadAndUnpack` (replacing direct clone).
- [ ] Implement `initializePortfolio` (git init logic).

### cli/package.json

- [ ] Add `adm-zip` dependency.
- [ ] Add `@types/adm-zip` devDependency.

---

## 17. Conclusion

This design provides a robust foundation for the Progy ecosystem. By moving to a centralized registry, we gain control over the distribution pipeline, enable versioning, and significantly improve the student experience by giving them clean, independent git repositories for their work. The use of Cloudflare D1 and R2 ensures this solution is scalable and cost-effective from Day 1.
